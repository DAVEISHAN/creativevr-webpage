# CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos

**[Project Page]()** | **[Paper](#)** | **[Dataset](#)**

> **Abstract:** Modern text-to-video (T2V) diffusion models can synthesize visually compelling clips, yet they remain brittle at fine-scale structure. CreativeVR is a diffusion-prior-guided video restoration framework for AI-generated (AIGC) and real videos with severe structural and temporal artifacts. Our deep-adapter-based method exposes a single precision knob that controls how strongly the model follows the input, smoothly trading off between precise restoration on standard degradations and stronger structure- and motion-corrective behavior on challenging content.

## ðŸŽ¥ Live Demo
Check out the interactive results on our **[Project Page]()**.
#top
## ðŸŽ“ Citation
If you find our work useful in your research, please consider citing:

```bibtex
@article{panambur2026creativevr,
    title={CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos},
    author={Panambur, Tejas and Dave, Ishan Rajendrakumar and Ge, Chongjian and Yumer, Ersin and Bai, Xue},
    journal={Preprint},
    year={2026}
}
```

## ðŸš€ Usage
*(Code and usage instructions coming soon)*

## ðŸ“„ License
This project is licensed under the MIT License.

